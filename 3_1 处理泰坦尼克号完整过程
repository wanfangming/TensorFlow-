import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

data = pd.read_csv('all/train.csv')

# 将原本数据中的三个无用属性去掉
data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']]

# 将缺省值（值为None）的年龄改为年龄均值
data['Age'] = data['Age'].fillna(data['Age'].mean())

# pd.factorize() 当有多个变量出现时，可以使用pandas.factorize( )
# 创建一些数字，来表示类别变量，对每一个类别映射一个ID
data['Cabin'] = pd.factorize(data.Cabin)[0]

data['Sex'] = [1 if x == 'male' else 0 for x in data.Sex]

data['p1'] = np.array(data['Pclass'] == 1).astype(np.int32)
data['p2'] = np.array(data['Pclass'] == 2).astype(np.int32)
data['p3'] = np.array(data['Pclass'] == 3).astype(np.int32)

del data['Pclass']

data['e1'] = np.array(data['Embarked'] == 'S').astype(np.int32)
data['e2'] = np.array(data['Embarked'] == 'C').astype(np.int32)
data['e3'] = np.array(data['Embarked'] == 'Q').astype(np.int32)

del data['Embarked']

data_train = data[['Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'p1', 'p2', 'p3', 'e1', 'e2', 'e3']]
data_target = data['Survived'].values.reshape(len(data), 1)
# 数据预处理完毕

# 定义两个占位符，None表示以后不一定非要只有那么多数据
x = tf.placeholder('float', shape=[None, 12])
y = tf.placeholder('float', shape=[None, 1])

weight = tf.Variable(tf.random_normal([12, 1]))
bias = tf.Variable(tf.random_normal([1]))
output = tf.matmul(x, weight) + bias
pred = tf.cast(tf.sigmoid(output) > 0.5, tf.float32)

# reduce_mean函数是将向量转换为标量值
loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=output))

train_step = tf.train.GradientDescentOptimizer(0.0003).minimize(loss)

accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, y), tf.float32))

# 开始处理test数据集
data_test = pd.read_csv('all/test.csv')
data_test = data_test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']]
data_test['Age'] = data_test['Age'].fillna(data['Age'].mean())
data_test['Cabin'] = pd.factorize(data_test.Cabin)[0]
data_test['Sex'] = [1 if x == 'male' else 0 for x in data_test.Sex]
data_test['p1'] = np.array(data_test['Pclass'] == 1).astype(np.int32)
data_test['p2'] = np.array(data_test['Pclass'] == 2).astype(np.int32)
data_test['p3'] = np.array(data_test['Pclass'] == 3).astype(np.int32)
del data_test['Pclass']
data_test['e1'] = np.array(data_test['Embarked'] == 'S').astype(np.int32)
data_test['e2'] = np.array(data_test['Embarked'] == 'C').astype(np.int32)
data_test['e3'] = np.array(data_test['Embarked'] == 'Q').astype(np.int32)
del data_test['Embarked']
# data_test.fillna(0, inplace=True)
# 处理完毕

# 读取真实结果
test_lable = pd.read_csv('all/gender_submission.csv')
test_lable = np.reshape(test_lable.Survived.values.astype(np.float32), (418, 1))

# 创建TensorFlow Session和初始化所有变量
sess = tf.Session()
sess.run(tf.global_variables_initializer())
# 每过一千步的loss值、训练正确率和测试正确率
loss_train = []
train_acc = []
test_acc = []


for i in range(25000):
    index = np.random.permutation(len(data_target))
    data_train = data_train.iloc[index]
    data_target = data_target[index]
    for n in range(len(data_target) // 100 + 1):
        batch_xs = data_train[n * 100: n * 100 + 100]
        batch_ys = data_target[n * 100: n * 100 + 100]
        sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})
    if i % 1000 == 0:
        loss_temp = sess.run(loss, feed_dict={x: batch_xs, y: batch_ys})
        loss_train.append(loss_temp)
        train_acc_temp = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys})
        train_acc.append(train_acc_temp)
        test_acc_temp = sess.run(accuracy, feed_dict={x: data_test, y: test_lable})
        test_acc.append(test_acc_temp)
        print(loss_temp, train_acc_temp, test_acc_temp)

# 画精度损失图，k-表示黑色线段
plt.plot(loss_train, 'k-')
plt.title('train loss')
plt.show()

# 训练准确率与测试准确率图，b-表示蓝色直线，r--表示红色虚线
plt.plot(train_acc, 'b-', label='train_acc')
plt.plot(test_acc, 'r--', label='test_acc')
plt.title('train and test accuracy')
plt.legend()
plt.show()
